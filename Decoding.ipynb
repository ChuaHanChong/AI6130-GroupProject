{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e2be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import FactualCorrectness\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60d25af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"rungalileo/ragbench\", \"hotpotqa\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e47461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which university did one of the key figures in the American documentary film, released in 2015, directed by Malcolm Ingram, pay for, before being drafted 18th overall pick for the New Jersey Nets?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59bf554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761038542.364265  822636 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "/tmp/ipykernel_822636/2935404805.py:1: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use the modern LLM providers instead: from ragas.llms.base import llm_factory; llm = llm_factory('gpt-4o-mini') or from ragas.llms.base import instructor_llm_factory; llm = instructor_llm_factory('openai', client=openai_client)\n",
      "  evaluator_llm = LangchainLLMWrapper(\n"
     ]
    }
   ],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e10709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824fd211d22f487c98f4b906eda753df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, quantization_config=bnb_config, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d1424",
   "metadata": {},
   "source": [
    "# DoLa Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54adbbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "100%|██████████| 2/2 [01:48<00:00, 54.01s/it]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 2\n",
    "dataset = []\n",
    "for d in tqdm(ds.select(range(num_samples)), total=num_samples):\n",
    "    question = d[\"question\"]\n",
    "    reference = d[\"response\"]\n",
    "\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.2,\n",
    "        custom_generate=\"custom_decoding/dola\",\n",
    "        trust_remote_code=True,\n",
    "        dola_layers='high',\n",
    "    )\n",
    "\n",
    "    response = tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[-1]:], skip_special_tokens=True)[0]\n",
    "\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\": question,\n",
    "            \"response\": response.strip(),\n",
    "            \"reference\": reference,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86be3e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54baf9891f64b5e95a3302c548c938b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761038667.709127  822636 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'factual_correctness(mode=f1)': 0.3750}\n"
     ]
    }
   ],
   "source": [
    "evaluation_dataset = Dataset.from_list(dataset)\n",
    "\n",
    "ragas_result = evaluate(evaluation_dataset, metrics=[FactualCorrectness()], llm=evaluator_llm)\n",
    "print(ragas_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6245f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which university did one of the key figures in...</td>\n",
       "      <td>(1963-1981)\\n\\nThe question appears to be a ri...</td>\n",
       "      <td>One of the key figures in the American documen...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Were both Léopold Eyharts and Ulrich Walter a ...</td>\n",
       "      <td>1. Léopold Eyharts\\n2. Ulrich Walter\\n\\nPlease...</td>\n",
       "      <td>No, only Léopold Eyharts was a General in the ...</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Which university did one of the key figures in...   \n",
       "1  Were both Léopold Eyharts and Ulrich Walter a ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  (1963-1981)\\n\\nThe question appears to be a ri...   \n",
       "1  1. Léopold Eyharts\\n2. Ulrich Walter\\n\\nPlease...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  One of the key figures in the American documen...   \n",
       "1  No, only Léopold Eyharts was a General in the ...   \n",
       "\n",
       "   factual_correctness(mode=f1)  \n",
       "0                          0.00  \n",
       "1                          0.75  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_result_df = ragas_result.to_pandas()\n",
    "ragas_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3619555c",
   "metadata": {},
   "source": [
    "# SLED Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bc4a9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:08<00:00, 34.01s/it]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 2\n",
    "dataset = []\n",
    "for d in tqdm(ds.select(range(num_samples)), total=num_samples):\n",
    "    question = d[\"question\"]\n",
    "    reference = d[\"response\"]\n",
    "\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.2,\n",
    "        custom_generate=\"custom_decoding/sled\",\n",
    "        trust_remote_code=True,\n",
    "        evolution_rate=2.0,\n",
    "        evolution_scale=10,\n",
    "        evolution_lower_bound=-1000.0,\n",
    "    )\n",
    "\n",
    "    response = tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[-1]:], skip_special_tokens=True)[0]\n",
    "\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\": question,\n",
    "            \"response\": response.strip(),\n",
    "            \"reference\": reference,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7329cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8f93da7cf640a88ce6bc1e96b1ccf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'factual_correctness(mode=f1)': 0.0000}\n"
     ]
    }
   ],
   "source": [
    "evaluation_dataset = Dataset.from_list(dataset)\n",
    "\n",
    "ragas_result = evaluate(evaluation_dataset, metrics=[FactualCorrectness()], llm=evaluator_llm)\n",
    "print(ragas_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b3defe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which university did one of the key figures in...</td>\n",
       "      <td>The question appears to contain a mix-up or co...</td>\n",
       "      <td>One of the key figures in the American documen...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Were both Léopold Eyharts and Ulrich Walter a ...</td>\n",
       "      <td>1. **Léopold Eyharts**  \\n2. **Ulrich Walter**...</td>\n",
       "      <td>No, only Léopold Eyharts was a General in the ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Which university did one of the key figures in...   \n",
       "1  Were both Léopold Eyharts and Ulrich Walter a ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The question appears to contain a mix-up or co...   \n",
       "1  1. **Léopold Eyharts**  \\n2. **Ulrich Walter**...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  One of the key figures in the American documen...   \n",
       "1  No, only Léopold Eyharts was a General in the ...   \n",
       "\n",
       "   factual_correctness(mode=f1)  \n",
       "0                           0.0  \n",
       "1                           0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_result_df = ragas_result.to_pandas()\n",
    "ragas_result_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI6130",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
