{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f16f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_854012/3941151926.py:16: UserWarning: \n",
      "********************************************************************************\n",
      "RAGatouille WARNING: Future Release Notice\n",
      "--------------------------------------------\n",
      "RAGatouille version 0.0.10 will be migrating to a PyLate backend \n",
      "instead of the current Stanford ColBERT backend.\n",
      "PyLate is a fully mature, feature-equivalent backend, that greatly facilitates compatibility.\n",
      "However, please pin version <0.0.10 if you require the Stanford ColBERT backend.\n",
      "********************************************************************************\n",
      "  from ragatouille import RAGPretrainedModel\n",
      "/data/hanchong/miniconda3/envs/AI6130/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import ContextRelevance, FactualCorrectness, Faithfulness\n",
    "from ragatouille import RAGPretrainedModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, Pipeline, pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4586f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"rungalileo/ragbench\", \"hotpotqa\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed1523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in knowledge base: 1550\n"
     ]
    }
   ],
   "source": [
    "RAW_KNOWLEDGE_BASE = []\n",
    "\n",
    "for d in ds:\n",
    "    for doc in d[\"documents\"]:\n",
    "        RAW_KNOWLEDGE_BASE.append(doc)\n",
    "\n",
    "RAW_KNOWLEDGE_BASE = [LangchainDocument(page_content=doc) for doc in set(RAW_KNOWLEDGE_BASE)]\n",
    "\n",
    "print(f\"Number of documents in knowledge base: {len(RAW_KNOWLEDGE_BASE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e71b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    RAW_KNOWLEDGE_BASE, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1508a6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9d01ccb6e54d9aa09207da651cf1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "READER_MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
    "\n",
    "READER_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b26878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a chatbot providing answers to user queries. You will be given one or more context documents, and a question. Use the information in the documents to answer the question.\n",
      "\n",
      "If the documents do not provide enough information for you to answer the question, then say \"The documents are missing some of the information required to answer the question.\" Don't quote any external knowledge that is not in the documents. Don't try to make up an answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "Answer the question using the provided context.\n",
      "\n",
      "Context:\n",
      "{context}\n",
      "\n",
      "Question: {question}<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a chatbot providing answers to user queries. You will be given one or more context documents, and a question. \\\n",
    "Use the information in the documents to answer the question.\n",
    "\n",
    "If the documents do not provide enough information for you to answer the question, then say \\\n",
    "\"The documents are missing some of the information required to answer the question.\" Don't quote any external knowledge that is \\\n",
    "not in the documents. Don't try to make up an answer.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Answer the question using the provided context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(prompt_in_chat_format, tokenize=False, add_generation_prompt=True)\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6afa398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hanchong/miniconda3/envs/AI6130/lib/python3.12/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "RERANKER = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "963d3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_rag(\n",
    "    question: str,\n",
    "    llm: Pipeline,\n",
    "    knowledge_index: FAISS,\n",
    "    reranker: Optional[RAGPretrainedModel] = None,\n",
    "    num_retrieved_docs: int = 30,\n",
    "    num_docs_final: int = 7,\n",
    ") -> Tuple[str, List[LangchainDocument]]:\n",
    "    print(\"=> Retrieving documents...\")\n",
    "    relevant_docs = knowledge_index.similarity_search(query=question, k=num_retrieved_docs)\n",
    "    relevant_docs = [doc.page_content for doc in relevant_docs]  # Keep only the text\n",
    "\n",
    "    if reranker:\n",
    "        print(\"=> Reranking documents...\")\n",
    "        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n",
    "        relevant_docs = [doc[\"content\"] for doc in relevant_docs]\n",
    "\n",
    "    relevant_docs = relevant_docs[:num_docs_final]\n",
    "\n",
    "    final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "        question=question, context=\"\\n\".join([\"- \" + doc for doc in relevant_docs])\n",
    "    )\n",
    "\n",
    "    print(\"=> Generating answer...\")\n",
    "    response = llm(final_prompt)[0][\"generated_text\"]\n",
    "    return response, relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "821849cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hanchong/miniconda3/envs/AI6130/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "100%|██████████| 1/1 [00:00<00:00, 37.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:26<00:26, 26.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 54.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:53<00:00, 26.71s/it]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 2\n",
    "dataset = []\n",
    "for d in tqdm(ds.select(range(num_samples)), total=num_samples):\n",
    "    question = d[\"question\"]\n",
    "    reference = d[\"response\"]\n",
    "    response, relevant_docs = answer_with_rag(question, READER_LLM, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER)\n",
    "\n",
    "    # relevant_docs = d['documents']  # For testing purpose, use reference docs as retrieved docs\n",
    "    # response = reference  # For testing purpose, use reference as response\n",
    "\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\": question,\n",
    "            \"retrieved_contexts\": relevant_docs,\n",
    "            \"response\": response,\n",
    "            \"reference\": reference,\n",
    "            \"adherence_score\": d[\"adherence_score\"],\n",
    "            \"relevance_score\": d[\"relevance_score\"],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de4dbfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_854012/789157977.py:17: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use the modern LLM providers instead: from ragas.llms.base import llm_factory; llm = llm_factory('gpt-4o-mini') or from ragas.llms.base import instructor_llm_factory; llm = instructor_llm_factory('openai', client=openai_client)\n",
      "  evaluator_llm = LangchainLLMWrapper(\n",
      "E0000 00:00:1761040581.335965  854012 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "# model_id = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "# evaluator_llm = LangchainLLMWrapper(\n",
    "#    HuggingFacePipeline(\n",
    "#        pipeline=pipeline(\n",
    "#            \"text-generation\",\n",
    "#            model=AutoModelForCausalLM.from_pretrained(model_id),\n",
    "#            tokenizer=AutoTokenizer.from_pretrained(model_id),\n",
    "#            device_map=\"auto\",\n",
    "#            max_new_tokens=32,\n",
    "#        )\n",
    "#    )\n",
    "# )\n",
    "\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933102fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4aae1e973e46c7a75583eca353f4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761040584.536398  854012 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'factual_correctness(mode=f1)': 0.2000, 'faithfulness': 0.8333, 'nv_context_relevance': 0.6250}\n"
     ]
    }
   ],
   "source": [
    "evaluation_dataset = Dataset.from_list(dataset)\n",
    "\n",
    "ragas_result = evaluate(evaluation_dataset, metrics=[FactualCorrectness(), Faithfulness(), ContextRelevance()], llm=evaluator_llm)\n",
    "print(ragas_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58fbc6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>nv_context_relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which university did one of the key figures in...</td>\n",
       "      <td>[Out to Win is an American documentary film, r...</td>\n",
       "      <td>One of the key figures in the American documen...</td>\n",
       "      <td>One of the key figures in the American documen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Were both Léopold Eyharts and Ulrich Walter a ...</td>\n",
       "      <td>[Léopold Eyharts (born April 28, 1957) is a Br...</td>\n",
       "      <td>No, both Léopold Eyharts and Ulrich Walter wer...</td>\n",
       "      <td>No, only Léopold Eyharts was a General in the ...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Which university did one of the key figures in...   \n",
       "1  Were both Léopold Eyharts and Ulrich Walter a ...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [Out to Win is an American documentary film, r...   \n",
       "1  [Léopold Eyharts (born April 28, 1957) is a Br...   \n",
       "\n",
       "                                            response  \\\n",
       "0  One of the key figures in the American documen...   \n",
       "1  No, both Léopold Eyharts and Ulrich Walter wer...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  One of the key figures in the American documen...   \n",
       "1  No, only Léopold Eyharts was a General in the ...   \n",
       "\n",
       "   factual_correctness(mode=f1)  faithfulness  nv_context_relevance  \n",
       "0                           0.0      0.666667                  0.50  \n",
       "1                           0.4      1.000000                  0.75  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_result_df = ragas_result.to_pandas()\n",
    "ragas_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629989c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"ragbench/ragbench\")\n",
    "\n",
    "from evaluation import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3641f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_input', 'retrieved_contexts', 'response', 'reference', 'adherence_score', 'relevance_score', 'faithfulness', 'context_relevance'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset = evaluation_dataset.add_column(\"faithfulness\", ragas_result[\"faithfulness\"])\n",
    "evaluation_dataset = evaluation_dataset.add_column(\"context_relevance\", ragas_result[\"nv_context_relevance\"])\n",
    "evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f7b150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hallucination_auroc': 1.0, 'relevance_rmse': np.float64(0.4615988003900188)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = calculate_metrics(\n",
    "    evaluation_dataset,\n",
    "    pred_adherence=\"faithfulness\",  # adherence_score\n",
    "    pred_context_relevance=\"context_relevance\",  # relevance_score\n",
    ")\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI6130",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
