{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import ContextRelevance, FactualCorrectness, Faithfulness\n",
    "from ragatouille import RAGPretrainedModel\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"self_reflection\")\n",
    "\n",
    "from CTRLEval.ctrleval import CTRLEval\n",
    "from evaluate.loop_eval_utils import evaluate_knowledge, evaluate_response\n",
    "from evaluate.sent_similarity import Sent_Similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3121b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrleval_scorer = CTRLEval(\n",
    "    iwf_dir=\"self_reflection/CTRLEval/iwf_full.txt\",\n",
    "    prompt_dir=\"self_reflection/CTRLEval/prompt/prompt_topic.txt\",\n",
    "    verbal_dir=\"self_reflection/CTRLEval/prompt/verbal_topic.txt\",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# Error: Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
    "# Ignore because Pegasus uses static, sinusoidal position embeddings (rather than learned embeddings) for both encoder and decoder.\n",
    "\n",
    "entailment_scorer = Sent_Similar()\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"cuda\", dtype=torch.bfloat16).eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "reranker = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5726ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = \"hotpotqa\"\n",
    "#ds_name = \"pubmedqa\"\n",
    "#ds_name = \"delucionqa\"\n",
    "ds = load_dataset(\"rungalileo/ragbench\", ds_name)\n",
    "print(len(ds[\"train\"]))\n",
    "print(len(ds[\"validation\"]))\n",
    "print(len(ds[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b320f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_VECTOR_DB_PATH = f\"vector_store/{EMBEDDING_MODEL_NAME.replace('/', '~')}_{ds_name}\"\n",
    "\n",
    "if os.path.isdir(KNOWLEDGE_VECTOR_DB_PATH):\n",
    "    print(\"Loading existing knowledge vector database...\")\n",
    "    KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(\n",
    "        KNOWLEDGE_VECTOR_DB_PATH,\n",
    "        embedding_model,\n",
    "        allow_dangerous_deserialization=True,\n",
    "        distance_strategy=DistanceStrategy.COSINE,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    RAW_KNOWLEDGE_BASE = []\n",
    "\n",
    "    for split in ds:\n",
    "        for d in ds[split]:\n",
    "            for doc in d[\"documents\"]:\n",
    "                RAW_KNOWLEDGE_BASE.append(doc)\n",
    "\n",
    "    RAW_KNOWLEDGE_BASE = list(set(RAW_KNOWLEDGE_BASE))\n",
    "    print(f\"Number of documents in knowledge base: {len(RAW_KNOWLEDGE_BASE)}\")\n",
    "\n",
    "    print(\"Creating knowledge vector database...\")\n",
    "    KNOWLEDGE_VECTOR_DATABASE = FAISS.from_texts(RAW_KNOWLEDGE_BASE, embedding_model, distance_strategy=DistanceStrategy.COSINE)\n",
    "    KNOWLEDGE_VECTOR_DATABASE.save_local(KNOWLEDGE_VECTOR_DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ecc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    no_number = False\n",
    "    no_aspect = False\n",
    "\n",
    "    max_loop = 1\n",
    "    max_knowledge_loop = 1\n",
    "    max_response_loop = 1\n",
    "    demo_num = 0\n",
    "\n",
    "    threshold_entailment = 0.8\n",
    "    threshold_fact = -1\n",
    "    threshold_consistency = -5\n",
    "\n",
    "    temperature = 1.0\n",
    "    top_p = 1\n",
    "    top_k = 1\n",
    "    num_beams = 1\n",
    "    max_new_tokens = 128\n",
    "    repetition_penalty = 1.0\n",
    "\n",
    "\n",
    "args = Args()\n",
    "args.max_loop = 3\n",
    "args.max_knowledge_loop = 3\n",
    "args.max_response_loop = 3\n",
    "args.demo_num = 0\n",
    "args.threshold_entailment = 0.8\n",
    "args.threshold_fact = -1.0\n",
    "args.threshold_consistency = -5\n",
    "args.max_new_tokens = 1024\n",
    "args.temperature = 1.0\n",
    "args.top_p = 0.90\n",
    "args.top_k = 50\n",
    "args.repetition_penalty = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_step(\n",
    "    model: AutoModelForCausalLM,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    messages: List[dict[str, str]],\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 0.2,\n",
    "    top_p: float = 0.9,\n",
    "    top_k: int = 50,\n",
    "    num_beams: int = 1,\n",
    "    repetition_penalty: float = 1.1,\n",
    "    dola_decoding: bool = False,\n",
    "    activation_dola_decoding: bool = False,\n",
    "    dola_layers: Union[str, list[int]] = \"high\",\n",
    "    sled_decoding: bool = False,\n",
    "    activation_sled_decoding: bool = False,\n",
    "    end_sled_decoding: bool = False,\n",
    "    evolution_rate: float = 2.0,\n",
    "    evolution_scale: int = 10,\n",
    "    evolution_lower_bound: float = -1000.0,\n",
    ") -> str:\n",
    "    formatted_chat = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n",
    "    if dola_decoding:\n",
    "        print(\"=> Using DOLA decoding...\")\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=temperature > 0,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_beams=num_beams,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            custom_generate=\"custom_decoding/dola\",\n",
    "            trust_remote_code=True,\n",
    "            dola_layers=dola_layers,\n",
    "        )\n",
    "    elif activation_dola_decoding:\n",
    "        print(\"=> Using Activation DOLA decoding...\")\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=temperature > 0,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_beams=num_beams,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            custom_generate=\"custom_decoding/activation_dola\",\n",
    "            trust_remote_code=True,\n",
    "            dola_layers=dola_layers,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "    elif sled_decoding:\n",
    "        print(\"=> Using SLED decoding...\")\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=temperature > 0,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_beams=num_beams,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            custom_generate=\"custom_decoding/sled\",\n",
    "            trust_remote_code=True,\n",
    "            evolution_rate=evolution_rate,\n",
    "            evolution_scale=evolution_scale,\n",
    "            evolution_lower_bound=evolution_lower_bound,\n",
    "        )\n",
    "    elif activation_sled_decoding:\n",
    "        print(\"=> Using Activation SLED decoding...\")\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=temperature > 0,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_beams=num_beams,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            custom_generate=\"custom_decoding/activation_sled\",\n",
    "            trust_remote_code=True,\n",
    "            evolution_rate=evolution_rate,\n",
    "            evolution_scale=evolution_scale,\n",
    "            evolution_lower_bound=evolution_lower_bound,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "    elif end_sled_decoding:\n",
    "        print(\"=> Using End-SLED decoding...\")\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=temperature > 0,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_beams=num_beams,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            custom_generate=\"custom_decoding/end_sled\",\n",
    "            trust_remote_code=True,\n",
    "            evolution_rate=evolution_rate,\n",
    "            evolution_scale=evolution_scale,\n",
    "            evolution_lower_bound=evolution_lower_bound,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "    else:\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=temperature > 0,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_beams=num_beams,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0][inputs[\"input_ids\"].size(1) :], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def knowledge_loop(\n",
    "    args: Args,\n",
    "    question: str,\n",
    "    retrieved_docs: List[str],\n",
    ") -> Tuple[str, List[Tuple[int, str, float]]]:\n",
    "    print(\"knowledge_loop\")\n",
    "\n",
    "    THRESHOLD_FACTUAL = args.threshold_fact\n",
    "    MAX_KNOWLEDGE_LOOP = args.max_knowledge_loop\n",
    "\n",
    "    candidates = []\n",
    "    history = []\n",
    "\n",
    "    retrieved_context = \"\\n\".join([\"- \" + doc for doc in retrieved_docs])\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are an AI language model designed to provide accurate, relevant, and comprehensive background knowledge based on the given question and retrieved context, with the ability to incorporate additional context when necessary. \\\n",
    "Sometimes, the retrieved context may not be sufficient to answer the question accurately. In such cases, you should use your general knowledge to supplement the information from the retrieved context.\"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'Provide background knowledge in one paragraph (approximately 400 words) to answer the question: \"{question}\", based on the following retrieved context:\\n{retrieved_context}',\n",
    "        },\n",
    "    ]\n",
    "    knowledge = generate_step(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        messages,\n",
    "        max_new_tokens=args.max_new_tokens,\n",
    "        temperature=args.temperature,\n",
    "        top_p=args.top_p,\n",
    "        top_k=args.top_k,\n",
    "        num_beams=args.num_beams,\n",
    "        repetition_penalty=args.repetition_penalty,\n",
    "        activation_sled_decoding=True,\n",
    "        evolution_rate=0.5,\n",
    "        evolution_scale=75,\n",
    "    )\n",
    "\n",
    "    loop_i = 0\n",
    "    if MAX_KNOWLEDGE_LOOP > 1:\n",
    "        factuality_score = evaluate_knowledge(model, args.demo_num, question, knowledge, tokenizer)\n",
    "        candidates.append([factuality_score, knowledge])\n",
    "        history.append([loop_i, knowledge, factuality_score])\n",
    "\n",
    "    loop_i += 1\n",
    "    while (loop_i < MAX_KNOWLEDGE_LOOP) and factuality_score < THRESHOLD_FACTUAL:\n",
    "        if args.no_aspect:\n",
    "            instruction = f\"Please refine the knowledge.\"\n",
    "        elif args.no_number:\n",
    "            instruction = f\"The knowledge is not strongly supported by empirical evidence. Please refine the knowledge to improve its factuality.\"\n",
    "        else:\n",
    "            instruction = f\"The factuality score for the knowledge is {factuality_score} less than {THRESHOLD_FACTUAL}, which means the knowledge is not strongly supported by empirical evidence. Please refine the knowledge to improve its factuality.\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI language model designed to provide accurate, relevant, and comprehensive background knowledge based on the given question and retrieved context, with the ability to incorporate additional context when necessary.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'The provided background knowledge for the question: \"{question}\" is \"{knowledge}\", based on the following retrieved context:\\n{retrieved_context}\".\\n\\n{instruction}\\nThe refined knowledge should be in one paragraph (approximately 400 words).',\n",
    "            },\n",
    "        ]\n",
    "        knowledge = generate_step(\n",
    "            model, \n",
    "            tokenizer, \n",
    "            messages,\n",
    "            max_new_tokens=args.max_new_tokens,\n",
    "            temperature=args.temperature,\n",
    "            top_p=args.top_p,\n",
    "            top_k=args.top_k,\n",
    "            num_beams=args.num_beams,\n",
    "            repetition_penalty=args.repetition_penalty,\n",
    "            activation_sled_decoding=True,\n",
    "            evolution_rate=0.5,\n",
    "            evolution_scale=75,\n",
    "        )\n",
    "\n",
    "        factuality_score = evaluate_knowledge(model, args.demo_num, question, knowledge, tokenizer)\n",
    "\n",
    "        candidates.append([factuality_score, knowledge])\n",
    "        history.append([loop_i, knowledge, factuality_score])\n",
    "        loop_i += 1\n",
    "\n",
    "    if (MAX_KNOWLEDGE_LOOP > 1) and factuality_score < THRESHOLD_FACTUAL:\n",
    "        candidates.sort()\n",
    "        return candidates[-1][-1], history\n",
    "    else:\n",
    "        return knowledge, history\n",
    "\n",
    "\n",
    "def response_loop(\n",
    "    args: Args,\n",
    "    question: str,\n",
    "    final_knowledge: str,\n",
    ") -> Tuple[str, List[Tuple[int, str, float, float]], float]:\n",
    "    print(\"response_loop\")\n",
    "\n",
    "    THRESHOLD_CONS = args.threshold_consistency\n",
    "    MAX_RESPONSE_LOOP = args.max_response_loop\n",
    "\n",
    "    candidates = []\n",
    "    entailment_score_question_list = []\n",
    "    history = []\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI language model designed to provide accurate, relevant, and comprehensive answers to questions based on the given background knowledge.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'Refer to the background knowledge: \"{final_knowledge}\" and answer the question: \"{question}\" with one paragraph.',\n",
    "        },\n",
    "    ]\n",
    "    response = generate_step(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        messages,\n",
    "        max_new_tokens=args.max_new_tokens,\n",
    "        temperature=args.temperature,\n",
    "        top_p=args.top_p,\n",
    "        top_k=args.top_k,\n",
    "        num_beams=args.num_beams,\n",
    "        repetition_penalty=args.repetition_penalty,\n",
    "        activation_sled_decoding=True,\n",
    "        evolution_rate=0.5,\n",
    "        evolution_scale=75,\n",
    "    )\n",
    "\n",
    "    loop_i = 0\n",
    "    if MAX_RESPONSE_LOOP > 1:\n",
    "        entailment_score_question, cons_score_knowledge = evaluate_response(entailment_scorer, ctrleval_scorer, question, response, final_knowledge)\n",
    "        candidates.append([(entailment_score_question + cons_score_knowledge) / 2, response])\n",
    "        entailment_score_question_list.append(entailment_score_question)\n",
    "        history.append([loop_i, response, entailment_score_question, cons_score_knowledge])\n",
    "\n",
    "    loop_i += 1\n",
    "    while loop_i < MAX_RESPONSE_LOOP and cons_score_knowledge < THRESHOLD_CONS:\n",
    "        if args.no_aspect:\n",
    "            instruction = f\"Please refine the response.\"\n",
    "        elif args.no_number:\n",
    "            instruction = f\"The alignment and consistency between response and knowledge are low. Please refine the response to improve its consistency.\"\n",
    "        else:\n",
    "            instruction = f\"The consistency score for the response is {cons_score_knowledge} less than {THRESHOLD_CONS}, which means the alignment and consistency between response and knowledge are low. Please refine the response to improve its consistency.\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI language model designed to provide accurate, relevant, and comprehensive answers to questions based on the given background knowledge.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f'The generated response for the question: \"{question}\" is \"{response}\" based on the background knowledge: \"{final_knowledge}\".\\n\\n{instruction}',\n",
    "            },\n",
    "        ]\n",
    "        response = generate_step(\n",
    "            model, \n",
    "            tokenizer, \n",
    "            messages,\n",
    "            max_new_tokens=args.max_new_tokens,\n",
    "            temperature=args.temperature,\n",
    "            top_p=args.top_p,\n",
    "            top_k=args.top_k,\n",
    "            num_beams=args.num_beams,\n",
    "            repetition_penalty=args.repetition_penalty,\n",
    "            activation_sled_decoding=True,\n",
    "            evolution_rate=0.5,\n",
    "            evolution_scale=75,\n",
    "        )\n",
    "\n",
    "        entailment_score_question, cons_score_knowledge = evaluate_response(entailment_scorer, ctrleval_scorer, question, response, final_knowledge)\n",
    "        candidates.append([(entailment_score_question + cons_score_knowledge) / 2, response])\n",
    "        entailment_score_question_list.append(entailment_score_question)\n",
    "        history.append([loop_i, response, entailment_score_question, cons_score_knowledge])\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    if MAX_RESPONSE_LOOP > 1 and cons_score_knowledge < THRESHOLD_CONS:\n",
    "        merge = zip(candidates, entailment_score_question_list)\n",
    "        merge = sorted(merge)\n",
    "        candidates, entailment_score_question_list = zip(*merge)\n",
    "        return candidates[-1][-1], history, entailment_score_question_list[-1]\n",
    "    else:\n",
    "        return response, history, entailment_score_question\n",
    "\n",
    "\n",
    "def reflection_loop(\n",
    "    args: Args,\n",
    "    question: str,\n",
    "    retrieved_docs: List[str],\n",
    ") -> Tuple[str, str, List[Tuple[int, str, float]], List[Tuple[int, str, float, float]]]:\n",
    "    all_history_knowledge, all_history_response = [], []\n",
    "\n",
    "    THRESHOLD_ENTAIL = args.threshold_entailment\n",
    "    MAX_LOOP = args.max_loop\n",
    "\n",
    "    candidates = []\n",
    "    main_loop_i = 0\n",
    "    print(f\"main_loop {main_loop_i}\")\n",
    "\n",
    "    final_knowledge, history_knowledge = knowledge_loop(args, question, retrieved_docs)\n",
    "    all_history_knowledge += history_knowledge\n",
    "\n",
    "    final_response, history_response, entailment_score_question = response_loop(args, question, final_knowledge)\n",
    "    all_history_response += history_response\n",
    "    candidates.append([entailment_score_question, final_knowledge, final_response])\n",
    "\n",
    "    main_loop_i += 1\n",
    "    while main_loop_i < MAX_LOOP and entailment_score_question < THRESHOLD_ENTAIL:\n",
    "        print(f\"main_loop {main_loop_i}\")\n",
    "        final_knowledge, history_knowledge = knowledge_loop(args, question, retrieved_docs)\n",
    "        all_history_knowledge += history_knowledge\n",
    "\n",
    "        final_response, history_response, entailment_score_question = response_loop(args, question, final_knowledge)\n",
    "        all_history_response += history_response\n",
    "        candidates.append([entailment_score_question, final_knowledge, final_response])\n",
    "        main_loop_i += 1\n",
    "\n",
    "    if (MAX_LOOP > 1) and entailment_score_question < THRESHOLD_ENTAIL:\n",
    "        candidates.sort()\n",
    "        final_knowledge, final_response = candidates[-1][1:]\n",
    "\n",
    "    return final_knowledge, final_response, all_history_knowledge, all_history_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e37ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_rag_reflection(\n",
    "    args: Args,\n",
    "    question: str,\n",
    "    use_reranker: bool = True,\n",
    "    num_retrieved_docs: int = 30,\n",
    "    num_docs_final: int = 7,\n",
    ") -> Tuple[str, List[str]]:\n",
    "    \"\"\"RAG with self-reflection\"\"\"\n",
    "\n",
    "    # Step 1: Retrieve documents\n",
    "    print(\"=> Retrieving documents...\")\n",
    "    relevant_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=question, k=num_retrieved_docs)\n",
    "    relevant_docs = [doc.page_content for doc in relevant_docs]\n",
    "\n",
    "    # Step 2: Rerank if available\n",
    "    if use_reranker:\n",
    "        print(\"=> Reranking documents...\")\n",
    "        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n",
    "        relevant_docs = [doc[\"content\"] for doc in relevant_docs]\n",
    "\n",
    "    relevant_docs = relevant_docs[:num_docs_final]\n",
    "\n",
    "    # Step 3: Generate response with self-reflection\n",
    "    print(\"=> Generating response with self-reflection...\")\n",
    "    _, final_response, _, _ = reflection_loop(args, question, relevant_docs)\n",
    "\n",
    "    return final_response, relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4813268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response, relevant_docs = answer_with_rag_reflection(args, ds[0]['question'], KNOWLEDGE_VECTOR_DATABASE, use_reranker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "dataset = []\n",
    "for d in tqdm(ds[\"test\"].select(range(num_samples)), total=num_samples, desc=\"Processing test samples\"):\n",
    "    question = d[\"question\"]\n",
    "    reference = d[\"response\"]\n",
    "\n",
    "    final_response, relevant_docs = answer_with_rag_reflection(args, question, use_reranker=True)\n",
    "\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\": question,\n",
    "            \"retrieved_contexts\": relevant_docs,\n",
    "            \"response\": final_response,\n",
    "            \"reference\": reference,\n",
    "            \"adherence_score\": d[\"adherence_score\"],\n",
    "            \"relevance_score\": d[\"relevance_score\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "output_dir = \"results/exp-3\"\n",
    "with open(os.path.join(output_dir, f\"{MODEL_NAME.replace('/', '~')}_{ds_name}_rag-responses_activation-sled-decoding_self-reflection-full.json\"), \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset = Dataset.from_list(dataset)\n",
    "\n",
    "ragas_result = evaluate(evaluation_dataset, metrics=[FactualCorrectness(), Faithfulness(), ContextRelevance()], llm=evaluator_llm)\n",
    "print(ragas_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_result_df = ragas_result.to_pandas()\n",
    "ragas_result_df.to_csv(os.path.join(output_dir, f\"{MODEL_NAME.replace('/', '~')}_{ds_name}_ragas-results_activation-sled-decoding_self-reflection-full.csv\"), index=False)\n",
    "#ragas_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe72bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"ragbench/ragbench\")\n",
    "\n",
    "from evaluation import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset = evaluation_dataset.add_column(\"faithfulness\", ragas_result[\"faithfulness\"])\n",
    "evaluation_dataset = evaluation_dataset.add_column(\"context_relevance\", ragas_result[\"nv_context_relevance\"])\n",
    "evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce80d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_metrics(\n",
    "    evaluation_dataset,\n",
    "    pred_adherence=\"faithfulness\",  # adherence_score\n",
    "    pred_context_relevance=\"context_relevance\",  # relevance_score\n",
    ")\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI6130",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
